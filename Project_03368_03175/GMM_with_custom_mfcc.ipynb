{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1M_yCf7Vj90",
        "outputId": "7ea3569b-48c8-4a41-8543-10156890c484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading path for mfcc features\n",
        "MFCC_dataset_path = \"/content/drive/MyDrive/Emotion_Recognition/mfcc_train.mat\""
      ],
      "metadata": {
        "id": "mVCqVJt9V57y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries to be used\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score, classification_report"
      ],
      "metadata": {
        "id": "tkgWQK0FV5cx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading mfcc data and printing the classes of emotions\n",
        "mfcc_data = scipy.io.loadmat(MFCC_dataset_path)\n",
        "emotion_categories = list(mfcc_data.keys())\n",
        "emotion_categories = [e for e in emotion_categories if not e.startswith(\"__\")]\n",
        "print(\"Emotion categories:\", emotion_categories)"
      ],
      "metadata": {
        "id": "A3av3RB9t8ZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ae5a82-db4d-4692-8e4f-9f18b262827c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Emotion categories: ['fear', 'happiness', 'sadness']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Gaussian Mixture Model for every emotion\n",
        "gmm_models = {}\n",
        "\n",
        "for emotion in emotion_categories:\n",
        "    mfcc_list = []\n",
        "    print(f\"Training GMM for emotion: {emotion}\")\n",
        "\n",
        "    for i in range(mfcc_data[emotion].shape[0]):\n",
        "        mfcc_array = np.array(mfcc_data[emotion][i])\n",
        "        mfcc_list.append(mfcc_array.T)\n",
        "\n",
        "    # Making dataset one uniform\n",
        "    dataset = np.vstack(mfcc_list)\n",
        "\n",
        "    # Ready-made GMM function\n",
        "    gmm = GaussianMixture(n_components=64, covariance_type='full', random_state=42, max_iter= 2000, init_params= 'kmeans')\n",
        "    gmm.fit(dataset)\n",
        "\n",
        "    gmm_models[emotion] = gmm\n",
        "\n",
        "print(\"GMMs trained for each emotion.\")\n"
      ],
      "metadata": {
        "id": "x3QtDHBOV5UR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4ed4e46-05da-4c43-8bf0-781a49fbb08e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GMM for emotion: fear\n",
            "Training GMM for emotion: happiness\n",
            "Training GMM for emotion: sadness\n",
            "GMMs trained for each emotion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_predictions = []\n",
        "for emotion in emotion_categories:\n",
        "    for i in range(mfcc_data[emotion].shape[0]):\n",
        "        mfcc_array = np.array(mfcc_data[emotion][i]).T\n",
        "\n",
        "        log_likelihoods = []\n",
        "        for model_emotion, model in gmm_models.items():\n",
        "            log_likelihoods.append(model.score(mfcc_array))\n",
        "\n",
        "        predicted_emotion = emotion_categories[np.argmax(log_likelihoods)]\n",
        "\n",
        "        train_predictions.append(predicted_emotion)"
      ],
      "metadata": {
        "id": "9Intzqx-V5Ju"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_true_labels = []\n",
        "for emotion in emotion_categories:\n",
        "    train_true_labels.extend([emotion] * mfcc_data[emotion].shape[0])\n",
        "\n",
        "train_accuracy = accuracy_score(train_true_labels, train_predictions)\n",
        "print(f\"Training Accuracy: {train_accuracy}\")\n",
        "\n",
        "train_conf_matrix = confusion_matrix(train_true_labels, train_predictions, labels=emotion_categories)\n",
        "print(\"Training Confusion Matrix:\")\n",
        "print(train_conf_matrix)"
      ],
      "metadata": {
        "id": "ZUtgyYg8V45x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3a9ecc-4c9c-4481-ce3e-c2dbac06832d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9850746268656716\n",
            "Training Confusion Matrix:\n",
            "[[112   0   0]\n",
            " [  1 111   0]\n",
            " [  2   2 107]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MFCC_test_dataset_audio = \"/content/drive/MyDrive/Emotion_Recognition/mfcc_test.mat\"\n",
        "mfcc_test_data = scipy.io.loadmat(MFCC_test_dataset_audio)\n",
        "\n",
        "emotion_categories_test = list(mfcc_test_data.keys())\n",
        "emotion_categories_test = [e for e in emotion_categories_test if not e.startswith(\"__\")]"
      ],
      "metadata": {
        "id": "pS_FLvGTWLcr"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for emotion in emotion_categories_test:\n",
        "    for i in range(mfcc_test_data[emotion].shape[0]):\n",
        "        mfcc_array = np.array(mfcc_test_data[emotion][i]).T\n",
        "        log_likelihoods = []\n",
        "        for model_emotion, model in gmm_models.items():\n",
        "            log_likelihoods.append(model.score(mfcc_array))\n",
        "\n",
        "        predicted_emotion = emotion_categories[np.argmax(log_likelihoods)]\n",
        "\n",
        "        true_labels.append(emotion)\n",
        "        predicted_labels.append(predicted_emotion)"
      ],
      "metadata": {
        "id": "j-UKxzr4WNNb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision (weighted): {precision}\")\n",
        "print(f\"Recall (weighted): {recall}\")\n",
        "print(f\"F1-score (weighted): {f1}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, predicted_labels, labels=emotion_categories))\n",
        "\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=emotion_categories)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "_DxMgevAWO2n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6382f332-ce7c-4115-86f1-4f5b12ea1341"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6666666666666666\n",
            "Precision (weighted): 0.5\n",
            "Recall (weighted): 0.6666666666666666\n",
            "F1-score (weighted): 0.5555555555555555\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fear       0.50      1.00      0.67         1\n",
            "   happiness       1.00      1.00      1.00         1\n",
            "     sadness       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         3\n",
            "   macro avg       0.50      0.67      0.56         3\n",
            "weighted avg       0.50      0.67      0.56         3\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1 0 0]\n",
            " [0 1 0]\n",
            " [1 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ami93lo0xThq"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}